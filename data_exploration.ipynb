{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration for Machine Learning Education Projects:\n",
    "\n",
    " * ## Image Captioning Problem\n",
    "\n",
    "### *Disclaimer:*\n",
    "* #### *Hardware:*\n",
    "* ###### CPU: Intel Core i5-7300HQ\n",
    "* ###### RAM: 16 GB\n",
    "* ###### GPU: Nvidia GTX 1050 | 2GB\n",
    "* #### *Keras Backend: Tensorflow 2.1 GPU*\n",
    "* #### *On this kernel, all models are already trained and loaded; however, Training specs are displayed for evidence purposes and metric visualization.* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Captioning Problem \n",
    "\n",
    "### Data Collection\n",
    "\n",
    "#### The next cell creates a .py file which will automatically download the datasets for this project. \n",
    "#### On terminal, inside the appropriate enviornment, run: (It will take between 30 min to two hours, depending on your internet speed and your bandwidth usage)\n",
    "#### ```python coco_data_collection.py``` or ```python3 coco_data_collection.py```, which ever works for you.\n",
    "\n",
    "#### The Data is provided by the Common Objects in Context ([COCO](https://cocodataset.org/#home)) Project; therefore, we have to follow [COCO's Terms of Use](https://cocodataset.org/#termsofuse) and [Flickr's Terms of Use](https://www.flickr.com/creativecommons/) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "folder = 'scripts/'\n",
    "if not os.path.isdir(folder):\n",
    "    os.makedirs(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting scripts/coco_data_collection.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile scripts/coco_data_collection.py\n",
    "import wget\n",
    "import os\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def downloadAndUnzip(url, zipFile, folder):\n",
    "    print(f'working on {zipFile}')\n",
    "    if not os.path.isfile(zipFile):\n",
    "        wget.download(url, zipFile) # download .zip file from url source\n",
    "    if not os.path.isdir(zipFile.replace('.zip','')):\n",
    "        with zipfile.ZipFile(zipFile, 'r') as zip_: # unzip in a given folder\n",
    "            for member in tqdm(zip_.infolist(), desc='Extracting'):\n",
    "                try:\n",
    "                    zip_.extract(member, folder)\n",
    "                except zipfile.error as e:\n",
    "                    pass\n",
    "    print(f'zip file {zipFile} has been downloaded and extracted in {folder}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # create data folder if inexistent\n",
    "    folder = 'data/'\n",
    "    if not os.path.isdir(folder):\n",
    "        os.makedirs(folder)\n",
    "        \n",
    "    urls = ['http://images.cocodataset.org/zips/train2014.zip',\n",
    "            'http://images.cocodataset.org/zips/val2014.zip',\n",
    "            'http://images.cocodataset.org/annotations/annotations_trainval2014.zip'] \n",
    "\n",
    "    zipFiles = ['data/train2014.zip',\n",
    "                'data/val2014.zip',\n",
    "                'data/annotations_trainval2014.zip']\n",
    "    \n",
    "    for url, zipFile in zip(urls, zipFiles):\n",
    "        downloadAndUnzip(url, zipFile, folder)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run in terminal\n",
    "# !python scripts/coco_data_collection.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration: Summary\n",
    "#### Image files: ``` data/train2014/*``` and ```data/val2014/*```\n",
    "#### JSON files: ``` data/annotations/captions_train2014.json``` and ```data/annotations/captions_val2014.json```\n",
    "\n",
    "#### Train2014 has 82,783 images and Val2014 has 40,504.\n",
    "\n",
    "#### So, in order to understand the hierarchical structure within each JSON file, we have to explore the keys which encode the dictionaries.  \n",
    "\n",
    "#### the main dictionary has five keys: 'info', 'images', 'licenses', 'categories', 'annotations'. The most important ones for this project are 'images' and 'annotations'. \n",
    "\n",
    "#### At least, numerically, both JSON's are consistent with the image folders. Later, it's ascertained that the images are named congruently with the databases. \n",
    "\n",
    "### Training Data Summary\n",
    "\n",
    "- #### 82,783 images;\n",
    "- #### each one with either five (82586), six (196) or seven (1) captions.\n",
    "- #### there are 414,113 captions.\n",
    "- #### Originally, there are no letters with special symbols (ticks, primes, diaresis) (English Language)\n",
    "- #### A homologated corpus to lower cases and deleting punctuation marks gives 23,130 unique words.\n",
    "- #### La longest Caption has 49 words, the shortest has 5 words and, on average, captions are 10.45 words long. Hence a positively skewed (right skewed) distribution is in place. \n",
    "- #### Regarding image sizes, the lowest height and width are 51 and 59 pixels respectively; however, maximum height and width are 640 pixels, each. The average width is 578 pixels and the average height is 438.6 pixels. Anyhow, both metrics have quasi-bimodal distributions with peaks aproximately around 500 and 640 pixels, each.\n",
    "\n",
    "## Validation Data Summary\n",
    "\n",
    "- #### 40,504 images;\n",
    "- #### each one with either five (40373), six (128) or seven (3) captions.\n",
    "- #### there are 202,654 captions.\n",
    "- #### Originally, there are no letters with special symbols (ticks, primes, diaresis) (English Language)\n",
    "- #### A homologated corpus to lower cases and deleting punctuation marks gives 17,350 unique words.\n",
    "- #### The longest Caption has 50 words, the shortest has 6 words and, on average, captions are 10.45 words long. Hence a positively skewed (right skewed) distribution is in place. \n",
    "- #### Regarding image sizes, the lowest height and width are 111 and 120 pixels respectively; however, maximum height and width are 640 pixels, each. The average width is 576.5 pixels and the average height is 485 pixels. Anyhow, both metrics have quasi-bimodal distributions with peaks aproximately around 470 and 640 pixels, each.\n",
    "\n",
    "## All previous conclusions were attained and pondered by running the following three cells. The third one will display a python-formatted report, delving more into each part of this exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import re\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell # All outputs are displayed for every cell\n",
    "InteractiveShell.ast_node_interactivity = \"none\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The folder data/annotations has 6 files.\n",
      "\t With file extesions: {'.json'}\n",
      "\n",
      " The folder data/models has 20 files.\n",
      "\t With file extesions: {'.h5'}\n",
      "\n",
      " The folder data/train2014 has 82783 files.\n",
      "\t With file extesions: {'.jpg'}\n",
      "\n",
      " The folder data/val2014 has 40504 files.\n",
      "\t With file extesions: {'.jpg'}\n",
      "\n",
      " For data/annotations/captions_train2014.json file\n",
      "\n",
      "\timages key has 82783 records, \n",
      "\t each with dict_keys(['license', 'file_name', 'coco_url', 'height', 'width', 'date_captured', 'flickr_url', 'id']) attributes\n",
      "\n",
      "\tannotations key has 414113 records, \n",
      "\t each with dict_keys(['image_id', 'id', 'caption']) attributes\n",
      "\n",
      " For data/annotations/captions_val2014.json file\n",
      "\n",
      "\timages key has 40504 records, \n",
      "\t each with dict_keys(['license', 'file_name', 'coco_url', 'height', 'width', 'date_captured', 'flickr_url', 'id']) attributes\n",
      "\n",
      "\tannotations key has 202654 records, \n",
      "\t each with dict_keys(['image_id', 'id', 'caption']) attributes\n",
      "\n",
      " For data/annotations/instances_train2014.json file\n",
      "\n",
      "\timages key has 82783 records, \n",
      "\t each with dict_keys(['license', 'file_name', 'coco_url', 'height', 'width', 'date_captured', 'flickr_url', 'id']) attributes\n",
      "\n",
      "\tannotations key has 604907 records, \n",
      "\t each with dict_keys(['segmentation', 'area', 'iscrowd', 'image_id', 'bbox', 'category_id', 'id']) attributes\n",
      "\n",
      " For data/annotations/instances_val2014.json file\n",
      "\n",
      "\timages key has 40504 records, \n",
      "\t each with dict_keys(['license', 'file_name', 'coco_url', 'height', 'width', 'date_captured', 'flickr_url', 'id']) attributes\n",
      "\n",
      "\tannotations key has 291875 records, \n",
      "\t each with dict_keys(['segmentation', 'area', 'iscrowd', 'image_id', 'bbox', 'category_id', 'id']) attributes\n",
      "\n",
      " For data/annotations/person_keypoints_train2014.json file\n",
      "\n",
      "\timages key has 82783 records, \n",
      "\t each with dict_keys(['license', 'file_name', 'coco_url', 'height', 'width', 'date_captured', 'flickr_url', 'id']) attributes\n",
      "\n",
      "\tannotations key has 185316 records, \n",
      "\t each with dict_keys(['segmentation', 'num_keypoints', 'area', 'iscrowd', 'keypoints', 'image_id', 'bbox', 'category_id', 'id']) attributes\n",
      "\n",
      " For data/annotations/person_keypoints_val2014.json file\n",
      "\n",
      "\timages key has 40504 records, \n",
      "\t each with dict_keys(['license', 'file_name', 'coco_url', 'height', 'width', 'date_captured', 'flickr_url', 'id']) attributes\n",
      "\n",
      "\tannotations key has 88153 records, \n",
      "\t each with dict_keys(['segmentation', 'num_keypoints', 'area', 'iscrowd', 'keypoints', 'image_id', 'bbox', 'category_id', 'id']) attributes\n",
      "\n",
      "About Training\n",
      "\t82586 images have 5 captions\n",
      "\t196 images have 6 captions\n",
      "\t1 images have 7 captions\n",
      "\n",
      "About Validation\n",
      "\t40373 images have 5 captions\n",
      "\t128 images have 6 captions\n",
      "\t3 images have 7 captions\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7343f2826e604aa5b17f194b659f9607",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/414113 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Unique Words: 23130\n",
      "Max Number of Words in a Caption: 49\n",
      "Min Number of Words in a Caption: 5\n",
      "Average Number of Words in all captions: 10.458350740015407\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c52fc7bd52774244b864b3377831fddd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/202654 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n",
      "Unique Words: 17350\n",
      "Max Number of Words in a Caption: 50\n",
      "Min Number of Words in a Caption: 6\n",
      "Average Number of Words in all captions: 10.452623683717075\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Training \n",
      "             license        height         width             id\n",
      "count  82783.000000  82783.000000  82783.000000   82783.000000\n",
      "mean       2.818054    483.590206    578.045794  290998.758900\n",
      "std        1.511456     96.855347     92.020402  167952.307935\n",
      "min        1.000000     51.000000     59.000000       9.000000\n",
      "25%        1.000000    426.000000    500.000000  144726.000000\n",
      "50%        3.000000    480.000000    640.000000  291797.000000\n",
      "75%        4.000000    512.000000    640.000000  435936.500000\n",
      "max        7.000000    640.000000    640.000000  581921.000000\n",
      "\n",
      " Validation \n",
      "             license        height         width             id\n",
      "count  40504.000000  40504.000000  40504.000000   40504.000000\n",
      "mean       2.826536    485.069944    576.541477  290741.634086\n",
      "std        1.494372     97.766584     91.872464  168164.031110\n",
      "min        1.000000    111.000000    120.000000      42.000000\n",
      "25%        1.000000    426.000000    500.000000  145585.000000\n",
      "50%        3.000000    480.000000    640.000000  290980.000000\n",
      "75%        4.000000    531.000000    640.000000  436397.250000\n",
      "max        7.000000    640.000000    640.000000  581929.000000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are the training images and annotations sets congruent? True\n",
      "Are the validation images and annotations sets congruent? True\n"
     ]
    }
   ],
   "source": [
    "# Explore folders within data/\n",
    "data = 'data/' \n",
    "folders = [''.join([data, folder]) for folder in os.listdir(data) if os.path.isdir(''.join([data, folder]))]\n",
    "for folder in folders:\n",
    "    files = os.listdir(folder)\n",
    "    print(f\"\\n The folder {folder} has {len(files)} files.\")\n",
    "    print(f\"\\t With file extesions: {set([os.path.splitext(file)[1] for file in files])}\")\n",
    "\n",
    "# Explore JSONs within annotations/\n",
    "annotations = ''.join([data, 'annotations/'])\n",
    "jsons = [''.join([annotations, js]) for js in os.listdir(annotations) if '.json' in js]\n",
    "\n",
    "for js in jsons:\n",
    "    with open(js, 'r') as rf:\n",
    "        d = json.load(rf)\n",
    "        \n",
    "    print(f'\\n For {js} file')\n",
    "    ks = ['images', 'annotations']\n",
    "    [print(f'\\n\\t{k} key has {len(d[k])} records, \\n\\t each with {d[k][0].keys()} attributes') for k in ks]\n",
    "    \n",
    "# Assign JSONs for further ETL:\n",
    "with open('data/annotations/captions_train2014.json', 'r') as rf:\n",
    "    tr_data = json.load(rf)\n",
    "    \n",
    "with open('data/annotations/captions_val2014.json', 'r') as rf:\n",
    "    v_data = json.load(rf)\n",
    "    \n",
    "# Harness Pandas for each dataset\n",
    "tr_caps = pd.DataFrame(tr_data['annotations'])\n",
    "v_caps = pd.DataFrame(v_data['annotations'])\n",
    "\n",
    "tr_imgs = pd.DataFrame(tr_data['images'])\n",
    "v_imgs = pd.DataFrame(v_data['images'])        \n",
    "\n",
    "# Assess number of captions per image\n",
    "print('\\nAbout Training')\n",
    "captions = pd.DataFrame(tr_caps['image_id'].value_counts())['image_id'].value_counts()\n",
    "[print(f'\\t{captions[i]} images have {i} captions') for i in captions.index]\n",
    "\n",
    "print('\\nAbout Validation')\n",
    "captions = pd.DataFrame(v_caps['image_id'].value_counts())['image_id'].value_counts()\n",
    "[print(f'\\t{captions[i]} images have {i} captions') for i in captions.index]\n",
    "\n",
    "# Exploreing Captions\n",
    "titles = [ 'Training', 'Validation']\n",
    "for i, caps in enumerate([tr_caps, v_caps]):\n",
    "    capExt = []# list to store all captions extensions: how many words p/ caption\n",
    "    corpus = ''# string to store every word in every caption\n",
    "    lc = caps['caption']\n",
    "    \n",
    "    for cap in tqdm(lc):\n",
    "        capExt.append(len(cap.split()))\n",
    "        corpus += ' ' + cap.lower() + ' '# convert to lowercase to decrease data latency\n",
    "        \n",
    "    corpus = re.split(r'\\W+', corpus)# remove punctuation marks\n",
    "    corpus = Counter(corpus)\n",
    "    \n",
    "    print(titles[i])\n",
    "    print(f'Unique Words: {len(corpus)}')\n",
    "    print(f'Max Number of Words in a Caption: {max(capExt)}')\n",
    "    print(f'Min Number of Words in a Caption: {min(capExt)}')\n",
    "    print(f'Average Number of Words in all captions: {np.mean(np.array(capExt))}')\n",
    "    plt.subplot(1, 2, i+1);\n",
    "    plt.hist(np.array(capExt));\n",
    "    plt.title(f'Words per Caption:\\n {titles[i]} Dist')\n",
    "plt.show();\n",
    "    \n",
    "    \n",
    "#Images descriptive statistics and distributions\n",
    "for i, imgs in enumerate([tr_imgs, v_imgs]):\n",
    "    print('\\n {} \\n'.format(titles[i]), imgs.describe())\n",
    "    \n",
    "    plt.subplot(2,2, 2*i+1);\n",
    "    plt.hist(imgs['height']);\n",
    "    plt.title(f'Height: {titles[i]}');\n",
    "    plt.subplot(2,2, 2*i+2);\n",
    "    plt.hist(imgs['width']);\n",
    "    plt.title(f'Width: {titles[i]}');\n",
    "plt.show();\n",
    "\n",
    "# ascertain file names are congruent with the databases. \n",
    "\n",
    "imgsTr = tr_imgs['file_name'].to_list()\n",
    "imgsV = v_imgs['file_name'].to_list()\n",
    "\n",
    "imgs_v = os.listdir('data/val2014/')\n",
    "imgs_tr = os.listdir('data/train2014/')\n",
    "\n",
    "print(f'Are the training images and annotations sets congruent? {set(imgsTr) == set(imgs_tr)}')\n",
    "print(f'Are the validation images and annotations sets congruent? {set(imgsV) == set(imgs_v)}')\n",
    "\n",
    "del imgsTr, imgsV, imgs_v, imgs_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell # All outputs are displayed for every cell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Data transformation by dint of our preliminary model: Google's Inception V.3â„¢\n",
    "\n",
    "### Training and Validation dictionaries structure: ``` {image_id: list(captions)} ```\n",
    "\n",
    "### Seize this process to transform captions into lowercase, erase punctuation marks and spaces on every string's ends.  \n",
    "\n",
    "### We find out that training and validation vocabulary has 4,189 words that are NOT shared. Going through a deeper processing, we can ameliorate this discrepancy. For instance, taking some percentage of the vocabulary with higher incidency or changing every word to its morphological root. Here, we'll get rid of all the words that appear only once on the Machine Learning Kernel. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d8216ff4e344379a7db34e8e7883492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/414113 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "351026ee50544990805b6cf6dcb5c397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/202654 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "82783"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "40504"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dictionaries and preprocess captions\n",
    "\n",
    "tr_captions, v_captions = dict(), dict()\n",
    "\n",
    "for dic, caps in zip([tr_captions, v_captions], [tr_caps, v_caps]):\n",
    "    ids_ = caps['image_id']\n",
    "    for id_ in tqdm(ids_):\n",
    "        lc = caps.loc[caps['image_id'] == id_, 'caption'].to_list()\n",
    "        id_ = str(id_)\n",
    "        while len(id_) < 12:\n",
    "            id_ = '0'+id_\n",
    "        dic[id_] = [' '.join(re.split(r'\\W+', c.lower())).strip() for c in lc]\n",
    "\n",
    "len(tr_captions)\n",
    "len(v_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "InteractiveShell.ast_node_interactivity = \"last\"# all o none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tr:  23129 Val:  17349\n",
      "Number of Words Not Shared Among Training and Validation Datasets: 4189\n",
      "Total words: 27318\n"
     ]
    }
   ],
   "source": [
    "# Assess if vocabulary ovelaps between Training and Validation data\n",
    "\n",
    "voc_tr, voc_v = set(), set()\n",
    "\n",
    "for dic, voc in zip([tr_captions, v_captions],[voc_tr, voc_v]):\n",
    "    for k in dic.keys():\n",
    "        [voc.update(cap.split()) for cap in dic[k]]\n",
    "\n",
    "print('Tr: ', len(voc_tr), 'Val: ', len(voc_v))\n",
    "\n",
    "\n",
    "n_voc = list(voc_v - voc_tr)\n",
    "        \n",
    "print('Number of Words Not Shared Among Training and Validation Datasets:', len(n_voc))\n",
    "voc = voc_tr.union(voc_v)\n",
    "print('Total words:', len(voc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13261316"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write Caption Files for ML\n",
    "\n",
    "lines = list()\n",
    "for k, caps in tr_captions.items():\n",
    "    [lines.append(k + ' ' + cap) for cap in caps]\n",
    "    \n",
    "con = '\\n'.join(lines)\n",
    "with open('data/tr_captions.txt', 'w') as file:\n",
    "    file.write(con)\n",
    "\n",
    "lines = list()\n",
    "for k, caps in v_captions.items():\n",
    "    [lines.append(k + ' ' + cap) for cap in caps]\n",
    "    \n",
    "con = '\\n'.join(lines)\n",
    "with open('data/v_captions.txt', 'w') as file:\n",
    "    file.write(con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The model's performance will be determined by several factor. One with which you can play is the size of the corpus. There are words that only appear once; therefore, it's reasonable to neglect them for these examples will overfit in spirit of unlikely occurences. Next I share a provisional code for corpus reduction based on a percentage you'd like to keep. \n",
    "```python\n",
    "# provisional code for vocabulary reduction according to an outlier theshold percentage(outlier_th)\n",
    "voc_tr, voc_v = '', ''\n",
    "\n",
    "for k, caps in tr_captions.items():\n",
    "    voc_tr += ' ' + ' '.join(caps) + ' '\n",
    "\n",
    "for k, caps in v_captions.items():\n",
    "    voc_v += ' ' + ' '.join(caps)\n",
    "\n",
    "voc_tr, voc_v = Counter(voc_tr.split()).most_common(), Counter(voc_v.split()).most_common()\n",
    "\n",
    "outlier_th = .99\n",
    "\n",
    "t_tr, t_v = 0, 0\n",
    "for _, c in voc_tr:\n",
    "    t_tr += c\n",
    "\n",
    "for _, c in voc_v:\n",
    "    t_v += c\n",
    "\n",
    "bag_por = 0\n",
    "n_W = 0\n",
    "new_voc_tr, new_voc_v = [], []\n",
    "\n",
    "for w,c in voc_tr:\n",
    "    if bag_por <= outlier_th:\n",
    "        n_W += c\n",
    "        bag_por = n_W/t_tr\n",
    "        new_voc_tr.append(w)\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "bag_por = 0\n",
    "n_W = 0\n",
    "\n",
    "for w,c in voc_v:\n",
    "    if bag_por <= outlier_th:\n",
    "        n_W += c\n",
    "        bag_por = n_W/t_v\n",
    "        new_voc_v.append(w)\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "print('New Tr: ', len(new_voc_tr), 'New Val: ', len(new_voc_v))\n",
    "\n",
    "\n",
    "new_n_voc = list(set(new_voc_v) - set(new_voc_tr))\n",
    "        \n",
    "print('Number of Words Not Shared Among Training and Validation New Datasets:', len(new_n_voc))\n",
    "new_voc = set(new_voc_tr).union(set(new_voc_v))\n",
    "print('New Total words:', len(new_voc))\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following processes concern the facts that this is meant to be run locally, the datasets are relatively massive and we want to use the Google's imagenet model, Inception V3. \n",
    "\n",
    "### The model will be explained in the Machine Learning kernel, however, some key features for this part are the following:\n",
    "\n",
    "* #### for the input, pictures should have 299 x 299 pixels\n",
    "* #### we'll get rid of the last layer so that we can connect it to the NLP layers\n",
    "\n",
    "### The datasets will be serialized using a GPU, but this can be done as well with a CPU. Serializing the datasets will make them more portable, easy to feed to the learning stage and less sensitive to data loss. \n",
    "\n",
    "### Both training and validation sets will be posited in Pickle files as feature vectors \n",
    "\n",
    "### Run the script in terminal so that you can keep using the notebook: \n",
    "### ```python scripts/datasets_to_pickles.py```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting scripts/datasets_to_pickles.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile scripts/datasets_to_pickles.py\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import numpy as np\n",
    "from numba import cuda\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.test.is_built_with_cuda()\n",
    "print(f'Using GPU: {tf.test.is_gpu_available(cuda_only=False, min_cuda_compute_capability=None)}')\n",
    "\n",
    "# Create a new model, by removing the last layer (output layer) from the inception v3\n",
    "model = tf.keras.applications.inception_v3.InceptionV3(weights='imagenet')\n",
    "model_new = keras.Model(model.input, model.layers[-2].output)\n",
    "\n",
    "def preprocess(image_path):\n",
    "    # Convert all the images to size 299x299 as expected by the inception v3 model\n",
    "    img = keras.preprocessing.image.load_img(image_path, target_size=(299, 299))\n",
    "    # Convert PIL image to numpy array of 3-dimensions\n",
    "    x = keras.preprocessing.image.img_to_array(img)\n",
    "    # Add one more dimension\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    # preprocess the images using preprocess_input() from inception module\n",
    "    x = keras.applications.inception_v3.preprocess_input(x)\n",
    "    return x\n",
    "\n",
    "# Function to encode a given image into a vector of size (2048, )\n",
    "def encode(image):\n",
    "    image = preprocess(image) # preprocess the image\n",
    "    fea_vec = model_new.predict(image) # Get the encoding vector for the image\n",
    "    fea_vec = np.reshape(fea_vec, fea_vec.shape[1]) # reshape from (1, 2048) to (2048, )\n",
    "    return fea_vec\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    data = \"data/\"\n",
    "    pickles = [\"encoded_train_images.pkl\", \"encoded_test_images.pkl\", \"encoded_final_images.pkl\"]\n",
    "    folders = [\"train2014/\", \"val2014/\", 'test_images/']\n",
    "    for folder, pick in zip(folders, pickles):\n",
    "        print(f'working on a pickle about {folder}')\n",
    "        if folder == 'test_images/':\n",
    "                pick = ''.join([folder, pick])\n",
    "        else: \n",
    "            folder = ''.join([data, folder])\n",
    "            pick = ''.join([data, pick])\n",
    "        if not os.path.isfile(pick):\n",
    "            dataset = [''.join([folder, file]) for file in os.listdir(folder)]\n",
    "\n",
    "            encoding = {}\n",
    "            for img in tqdm(dataset):\n",
    "                encoding[img.replace(folder,'')] = encode(img)\n",
    "\n",
    "            # Save the bottleneck train features to disk\n",
    "            with open(pick, \"wb\") as encoded_pickle:\n",
    "                pickle.dump(encoding, encoded_pickle)\n",
    "            \n",
    "        print(f'{folder} has been serialized inside {pick}')\n",
    "        dataset_features = pickle.load(open(pick, \"rb\"))\n",
    "        print(f'Photos {folder}: {len(dataset_features)}')\n",
    "        \n",
    "        # clear GPU memory if needed\n",
    "#         del dataset_features\n",
    "#         device = cuda.get_current_device()\n",
    "#         device.reset()\n",
    "#         physical_devices = tf.config.list_physical_devices('GPU') \n",
    "#         tf.test.is_built_with_cuda()\n",
    "#         print(f'Using GPU: {tf.test.is_gpu_available(cuda_only=False, min_cuda_compute_capability=None)}')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run in terminal\n",
    "# !python scripts/datasets_to_pickles.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b82966cb412374646c94b2ad3d591a1f1897291d204baf4f6ad4618e57757e13"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
